{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home lab","text":"<p>All the necessary to provision, configure and manage my home lab.</p> <p>Before using the home lab, you initialize the environments by executing a manual process. After the initalization process completes, automated processes take care of applying provisioning and configuration changes to the environments.</p>"},{"location":"#get-started","title":"Get started","text":"<p>For more information about how to set up the lab, see:</p> <ul> <li>Initialize the home lab on physical hardware.</li> </ul>"},{"location":"#architecture","title":"Architecture","text":"<p>For more information about the architecture of the lab, see Architecture.</p>"},{"location":"architecture/","title":"Home lab architecture overview","text":"<p>This document describes the architecture of the lab.</p> <p>The following diagram shows the architectural layers that compose the lab:</p> <pre><code>+---------------------+\n|      Workloads      |\n|---------------------|\n|       Platform      |\n|---------------------|\n|  System | External  |\n|---------------------|\n|      Bootstrap      |\n|---------------------|\n| Hardware management |\n|---------------------|\n|  Physical hardware  |\n+---------------------+\n</code></pre> <p>The scope of each layer is as follows:</p> <ul> <li><code>Workloads</code>: manage user-facing applications.</li> <li><code>Platform</code>: manage essential components to run workloads.</li> <li><code>External</code>: manage external services.</li> <li><code>System</code>: manage critical system components.</li> <li><code>Bootstrap</code>: manage automated configuration and deployment processes.</li> <li><code>Hardware management</code>: manage physical hardware. Example: IPMI, Redfish, KVM.</li> <li><code>Physical hardware</code>: provide hardware resources.</li> </ul>"},{"location":"architecture/#support-content","title":"Support content","text":"<p>This repository includes the following content to support provisioning, configuration, and deployment processes:</p> <ul> <li>Development environment container configuration in the <code>.devcontainer</code> directory.</li> <li>GitHub-specific configuration in the <code>.github</code> directory.</li> <li>Configuration for each architectural layer and support tooling in the <code>config</code> directory.</li> <li>Container image descriptors in the <code>docker</code> directory.</li> <li>Documentation site in the <code>docs</code> directory.</li> <li>Source of the documentation site in the <code>docs-src</code> directory.</li> <li>Operational scripts in the <code>scripts</code> directory.</li> <li>Tests in the <code>test</code> directory.</li> </ul>"},{"location":"architecture/network-configuration/","title":"Network configuration","text":""},{"location":"architecture/network-configuration/#network-subnets","title":"Network subnets","text":"<p>Network subnet planning strategy: <code>10.SITE_ID.VLAN_ID.HOST/24</code></p> <ul> <li>Main subnet: <code>10.0.0.0/8</code></li> </ul>"},{"location":"architecture/network-configuration/#dns-zones-dns-servers-dns-resolvers-and-dhcp-servers","title":"DNS zones, DNS servers, DNS resolvers, and DHCP servers","text":"<p>In this section, we describe the configuration of DNS zones, DNS servers, and DNS resolvers.</p>"},{"location":"architecture/network-configuration/#dns-zones","title":"DNS zones","text":"<ul> <li>Root DNS zone: <code>ferrari.how</code></li> <li>Home lab subdomain: <code>lab.ferrari.how</code></li> <li>Edge home lab subdomain: <code>edge.lab.ferrari.how</code></li> </ul>"},{"location":"architecture/network-configuration/#dns-servers","title":"DNS servers","text":"<p>This environment contains the following DNS servers:</p> <ul> <li>Cloudflare DNS servers that act as authoritative name servers for the root DNS   zone.</li> <li>A dnsmasq instance running on   the default gateway. It responds to DNS queries for the   <code>edge.lab.ferrari.how</code> zone, and returns authoritative answers from DHCP   leases   (source),   even if it doesn't run as an authoritative name server for the   <code>edge.lab.ferrari.how</code> zone.</li> </ul>"},{"location":"architecture/network-configuration/#dns-resolvers","title":"DNS resolvers","text":"<p>This environment contains the following DNS resolvers:</p> <ul> <li>A dnsmasq instance running on the default gateway acts as a private, non   recursive, caching, DNS resolver that uses   Google Public DNS, as a   public, recursive, caching DNS resolver.</li> <li>An unbound instance acts as a   private, recursive, caching DNS resolver.</li> </ul>"},{"location":"architecture/network-configuration/#dhcp-servers","title":"DHCP servers","text":"<p>This environment contains the following DHCP servers:</p> <ul> <li> <p>A dnsmasq instance running on the default gateway with the following configuration:</p> </li> <li> <p>Subnet: <code>10.0.0.0/8</code></p> </li> <li>Gateway: <code>10.0.0.1</code></li> </ul>"},{"location":"architecture/references/","title":"References","text":"<ul> <li>khuedoan/homelab</li> </ul>"},{"location":"guides/capture-proxmox-vm-network-traffic/","title":"Capture network traffic of a Proxmox VM","text":"<p>In order to capture the network traffic that goes through a network interface of a Proxmox VM, do the following:</p> <ol> <li>Get the Proxmox VM ID.</li> <li>Get the Proxmox VM interface name.</li> <li>On the Proxmox node that hosts the VM, check that there's a <code>tap</code> network    interface named <code>tap&lt;VM_ID&gt;i&lt;NET_INTERFACE_ID&gt;</code>.</li> <li>On the Proxmox node that hosts the VM, run <code>tcpdump</code> in order to capture    network traffic to a file:</li> </ol> <pre><code>tcpdump -i tap&lt;VM_ID&gt;i&lt;NET_INTERFACE_ID&gt; -n -w &lt;filename&gt;.pcap\n</code></pre> <p>Source: https://www.apalrd.net/posts/2023/tip_pcap/</p>"},{"location":"guides/configure-monitoring/","title":"Monitoring","text":"<p>To monitor the status of the home lab, the automated provisioning and configuration process deploy a monitoring agent on each home lab node, and a backend to collect data coming from the monitoring agents.</p>"},{"location":"guides/configure-monitoring/#import-grafana-dashsboards","title":"Import Grafana dashsboards","text":"<p>In its current state, Grafana doesn't support automatic import of dashboards that a datasource ships, so you need to import those dashboards manually. To import Grafana dashboards that ship with a datasource, do the following:</p> <ol> <li>Open Grafana.</li> <li>Open the datasource settings.</li> <li>Select a datasource.</li> <li>Open the <code>Dashboards</code> panel.</li> <li>Import the dashboards.</li> </ol>"},{"location":"guides/configure-network-shares/","title":"Configure network shares","text":"<p>To allow access to Samba network shares, do the following:</p> <ol> <li>Create a Linux system user.</li> <li>Add the user to the Samba database:</li> </ol> <pre><code>sudo smbpasswd -a \"${USER}\"\n</code></pre>"},{"location":"guides/configure-tailscale/","title":"Tailscale configuration","text":"<p>In this section, you configure new hosts to join a Tailscale network.</p>"},{"location":"guides/configure-tailscale/#tailscale-authentication-keys","title":"Tailscale authentication keys","text":"<ul> <li>If you want to automate authentication, you can specify an authentication key   for each host using the <code>tailscale_authkey</code> variable. For more information   about Tailscale authentication keys, see   Authentication keys.   The alternative is to manually run the <code>tailscale up</code> command on the host,   and follow the instructions to authenticate the host.</li> <li>If you prefer that the key for a particular host doesn't expire, you can   disable   Tailscale key expiration.</li> </ul>"},{"location":"guides/configure-tailscale/#enable-subnet-routes-or-exit-nodes-in-the-tailscale-console","title":"Enable subnet routes or exit nodes in the Tailscale console","text":"<p>If a Tailscale host advertises routes or advertises itself as an exit node, you need to enable these features in the Tailscale console or using the Tailscale API. For more information, see:</p> <ul> <li>Subnet routers and traffic relay nodes</li> <li>Exit nodes</li> </ul>"},{"location":"guides/container-migration/","title":"Container migration playbook","text":"<p>If you need to migrate containers and data between hosts, do the following:</p> <ol> <li>Set the <code>configure_xxxxx</code> variable for the target host to <code>true</code> to prepare the target host.</li> <li>Set the <code>start_xxxxx</code> variable for the target host to <code>false</code> because we don't want to start any services    before copying data.</li> <li>Run Ansible. With the above configuration, it will prepare the target host without starting any service.</li> <li>Set the <code>stop_xxxxx</code> variable for the source host to <code>true</code> to stop the service we're migrating.</li> <li>Run Ansible.</li> <li>Copy data from the source host to the target host. You can use <code>scripts/migrate-container-data.sh</code> script to transfer data from    one host to another.</li> <li>Remove the <code>start_xxxxx</code> from the target host configuration because it defaults to the <code>configure_xxxxx</code> value, which is set to <code>true</code>.</li> <li>Run Ansible.</li> <li>Remove the <code>stop_xxxxx</code> variable from the source host configuration.</li> <li>Remove the <code>configure_xxxxx</code> variable from the source host configuration.</li> <li>Run Ansible.</li> <li>Commit the changes in the repository.</li> </ol>"},{"location":"guides/container-migration/#data-migration-examples","title":"Data migration examples","text":"<p>These examples assume that the current working directory is the root of this repository.</p> <p>To migrate one directory from one host to another:</p> <pre><code>scripts/migrate-container-data.sh \"user@source.host\" \"/source/directory\" \"user2@target.host\" \"/destination\"\n</code></pre>"},{"location":"guides/copy-jinja-templates/","title":"Copy Jinja templates as they are","text":"<p>If you need to copy Jinja templates with the Ansible Template Module, you can configure Ansible to change the variable start and end prefixes inside the template by adding a special header.</p> <p>For example:</p> <pre><code>#jinja2:variable_start_string:'[%', variable_end_string:'%]'\n</code></pre> <p>Changes the default variable start and end prefixes from <code>{{</code> and <code>}}</code> to <code>[%</code> and <code>%]</code>.</p>"},{"location":"guides/expand-partition-debian/","title":"Expand a partition and a filesystem on Debian","text":"<ol> <li>Backup the current partition table:</li> </ol> <pre><code>sfdisk -d /dev/sda &gt; sda_partition_bakup.dmp\n</code></pre> <ol> <li>Get details about the changes to the partition table to apply (dry-run) to    see what will be changed:</li> </ol> <pre><code>growpart -N /dev/sda 1\n</code></pre> <ol> <li>Apply changes to the partition table:</li> </ol> <pre><code>growpart /dev/sda 1\n</code></pre> <ol> <li>Resize the file system:</li> </ol> <pre><code>resize2fs /dev/sdb1\n</code></pre> <ol> <li>Check the file system size:</li> </ol> <pre><code>df -h\n</code></pre>"},{"location":"guides/linux-disk-setup/","title":"Setup disks, partitions, and filesystems on Linux","text":"<ul> <li>Get the list of block devices: <code>lsblk</code></li> <li>Get the attributes of a block device: <code>blkid &lt;device&gt;</code></li> </ul>"},{"location":"guides/useful-linux-admin-commands/","title":"Useful Linux administration notes","text":""},{"location":"guides/useful-linux-admin-commands/#debian","title":"Debian","text":""},{"location":"guides/useful-linux-admin-commands/#os-package-management","title":"OS package management","text":"<ul> <li>Get the versions that are available to install of a package: <code>apt-cache madison &lt;package-name&gt;</code></li> <li>Install a specific package version: <code>apt-get install &lt;package-name&gt;=&lt;package-version-number&gt;</code></li> <li>The package update logs are in <code>/var/log/apt/history.log</code></li> </ul>"},{"location":"guides/useful-linux-admin-commands/#networking","title":"Networking","text":"<ul> <li>Get the list of open ports on a system (with superuser privileges, it also   returns process information): <code>sudo netstat -nlp</code></li> </ul>"},{"location":"guides/useful-linux-admin-commands/#restic","title":"Restic","text":"<ul> <li>Open a shell in the Restic container:</li> </ul> <pre><code>sudo docker compose --file /etc/ferrarimarco-home-lab/restic/compose.yaml run --build --interactive --rm --entrypoint /bin/bash restic-backup-workloads\n</code></pre>"},{"location":"guides/useful-proxmox-commands/","title":"Proxmox admin notes","text":"<ul> <li>Check if there are cloud-init datasource updates: <code>qm cloudinit pending &lt;VM_ID&gt;</code></li> <li>Update cloud-init datasource: <code>qm cloudinit update &lt;VM_ID&gt;</code></li> <li>Get the next proxmox VM ID: <code>pvesh get /cluster/nextid</code></li> <li>Get the list of PCI devices of a given Proxmox host: <code>pvesh get /nodes/{nodename}/hardware/pci --pci-class-blacklist \"\"</code></li> <li>Delete the EFI disk: <code>qm set &lt;VM_ID&gt; -delete efidisk0</code></li> </ul>"},{"location":"guides/useful-proxmox-commands/#disable-secure-boot","title":"Disable Secure Boot","text":"<p>Either enter the UEFI console and disable Secure Boot manually, or delete the EFI disk, and recreate it without the <code>pre-enrolled-keys=1</code> option.</p> <p>Notes:</p> <ul> <li>Secure Boot prevents unsigned kernel modules from loading.   Example: Coral PCIe modules (<code>apex</code>, <code>gasket</code>)</li> </ul>"},{"location":"guides/useful-proxmox-commands/#expand-disk-filesystem-and-partition","title":"Expand disk, filesystem, and partition","text":"<p>See: https://pve.proxmox.com/wiki/Resize_disks.</p>"},{"location":"installation/production/","title":"Initialize the home lab","text":"<p>To initialize the home lab, you need a controller, a machine that runs the initialization process.</p> <p>On the controller, you need the following software tools:</p> <ul> <li>Git. Tested with Git version &gt;= <code>2.25.0</code>.</li> <li>An OCI container runtime, such as Docker. Tested with Docker version &gt;= <code>20.10</code>.</li> <li>A connection to an IP network that can route packets to the internet.</li> </ul> <p>To initialize the home lab, do the following:</p> <ol> <li>Clone this repository.</li> <li>Change the working directory to the root of the cloned repository.</li> <li>Provision new, physical hosts.</li> <li>Run the <code>scripts/run-ansible.sh</code> script.</li> </ol>"},{"location":"installation/production/provision-new-hosts/","title":"Provision new hosts","text":"<p>This document is about the steps that are necessary to prepare new hosts for the home lab. We define this process as <code>provisioning new hosts</code>.</p> <p>The provisioning process is as follows:</p> <ul> <li>Gather information about the host:</li> <li>Unique name to assign to the host.</li> <li>MAC address of each network interface.</li> <li>Name of each network interface.</li> <li>Static IP address to assign to each network interface.</li> <li>Boot disk name.</li> <li>Update the BIOS and UEFI firmware to the latest available version.</li> <li>Enable network boot.</li> <li>Enable Wake-on-LAN.</li> <li>Enable hardware-assisted virtualization capabilities.</li> <li>Add the machine to the inventory.</li> </ul> <p>For hosts that support it, we automate the setup using an out-of-band configuration mechanisms, such as Intelligent Platform Management Interface (IPMI), or Redfish. Off-the-shelf, consumer hardware rarely support these configuration mechanisms, so you may need to manually complete some configuration steps to prepare a host to join the home lab.</p> <p>In this document, we provide information about the manual steps to provision the following types of hosts:</p> <ul> <li>Raspberry Pi 4</li> </ul>"},{"location":"installation/production/provision-new-hosts/#raspberry-pi-4","title":"Raspberry Pi 4","text":"<p>This section is about the manual configuration steps for Raspberry Pi 4 hosts.</p>"},{"location":"installation/production/provision-new-hosts/#update-and-configure-the-raspberry-pi-4-bootloader","title":"Update and configure the Raspberry Pi 4 bootloader","text":"<p>To update the bootloader on the Raspberry Pi 4 EEPROM and configure the boot order when not using Raspberry Pi OS, do the following:</p> <ol> <li>Download the latest release of rpi-eeprom.    There are different boot order configurations available, as configured    here.</li> <li>Flash the bootloader disk image on a removable flash drive. For more information about flashing Raspberry Pi OS    images to a SD card, refer to Raspberry Pi: Getting started.</li> <li>Insert the SD card in a powered off Raspberry Pi 4.</li> <li>Wait for the activity LED to steadily flash green.</li> <li>Power the Raspberry Pi off.</li> </ol>"},{"location":"installation/production/provision-new-hosts/#configure-raspberry-pi-hosts-running-raspberry-pi-os","title":"Configure Raspberry Pi hosts running Raspberry Pi OS","text":"<p>To update the configuration of a Raspberry Pis running Raspberry Pi OS, refer to Raspberry Pi Documentation.</p> <p>For example, you may need to change the hostname of a newly provisioned node before adding it to the set of automatically configured nodes.</p>"},{"location":"installation/production/provision-new-hosts/#configure-ssh-authentication","title":"Configure SSH authentication","text":"<p>For newly provisioned Raspberry Pis, you might have to authenticate a SSH connection using a password instead of a key. To authenticate with a password, add the <code>--ask-pass --connection paramiko</code> options to the Ansible command you're running.</p> <p>By using Paramiko to connect to a host using SSH, you can authenticate using a password without having the <code>sshpass</code> program installed on the host that runs Ansible.</p>"}]}